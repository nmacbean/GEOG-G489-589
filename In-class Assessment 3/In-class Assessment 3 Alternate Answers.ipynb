{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G489/589 Advanced Geospatial Data Analysis in Python: In-class Assessment 3\n",
    "### Alternate Exam\n",
    "**Indiana University  \n",
    "Spring 2019  \n",
    "Dr. Natasha MacBean**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 (Question and Answer Section - 20 points)\n",
    "Double click on each markdown box to write the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What python or numpy function would you use to create a numerical array that started with the number 1 and ended with the number 10 (with a step of 1 for each number)? **[1 point]**\n",
    "\n",
    "ANSWER:  \n",
    "range(1,11)\n",
    "np.arange(1,11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Which library and method would you use to create a list containing all the .csv files you have in a given directory. **[1 point]**\n",
    "\n",
    "ANSWER: glob.glob(\"\\*.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. You have a numerical 3-dimensional array of floats called \"data\", which consists of the dimensions (ntsteps, nrows, ncols), where ntsteps is the number of timesteps, and nrows/ncols are the number of rows/columns. Write the numpy function you would use to calculate the standard deviation over the column dimension. **[1 point]**\n",
    "\n",
    "ANSWERR: np.std(data, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. What is the numpy function for calculating a sum over a *masked* array? **[1 point]**\n",
    "\n",
    "ANSWER: np.ma.sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. You have a 1-dimensional numerical array of length 200. What numpy function would you use to convert this array into a 2-dimensional array with 2 rows and 100 columns? (*For now do not worry about the order that it is filling out the rows and columns)*. **[1 point]**\n",
    "\n",
    "ANSWER: array.reshape((2,100)) or array = np.reshape(array, (2,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. You know that each of the .csv files in your filelist has the format \"site_name.csv\" (where \"site_name\" is the name of each site in the list). Write a loop that loops over the filelist and extracts the **site name for each site** into a new list called \"sites\" using the method string.split **[2 points]**\n",
    "\n",
    "ANSWER:   \n",
    "sites = []  \n",
    "for f in filelist:  \n",
    "    sites.append(f.split('.')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Which numpy function would you use to check the sizes of all dimensions of an array? **[1 point]**\n",
    "\n",
    "ANSWER: np.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. You have two variables: a = 100 and b = 25. Write an **if** statement to check if b is less than or equal to a, and prints \"ok\" if that statement is true, **else** if the statement is not true, it prints \"not ok\". **[1 point]**\n",
    "\n",
    "ANSWER:   \n",
    "if b <= a:  \n",
    "    print(\"ok\")  \n",
    "else:  \n",
    "    print(\"not ok\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Write out both the steps needed, and the code you would use, to perform a KMeans clustering algorithm to a set of data that contains 1000 observations (nsamples or nrows) and 10 features (nfeatures or ncols). Create 4 clusters and save your resultant cluster labels to an array called \"labels4\".  Your input data are in a numerical floating point arrray in a file called \"data.txt\". There are no column headings in the data.txt file. Describe the steps you would take to complete this task from the beginning, including importing the library and reading in the data etc. For each step also write the code you would need. *Note: Do not execute the code, just write down the steps you would take and the syntax of code you would use.* **[10 points]**\n",
    "\n",
    "ANSWER:\n",
    "- *# load the libraries needed*   \n",
    "from sklearn.cluster import KMeans  \n",
    "import numpy as np  \n",
    "- *# load the data using np.loadtxt as they are saved as a simple numerical array*  \n",
    "data = np.loadtxt(\"data.txt\")  \n",
    "- *# first set-up the KMeans model*  \n",
    "model = KMeans(n_clusters=4)  \n",
    "- *# fit the data to the model*   \n",
    "model.fit(data)  \n",
    "- *# label the clusters in the model and save it to an arrray called \"labels2\"*   \n",
    "labels2 = model.predict(data)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Following on from the previous question, what would the length of the final array \"labels4\" be? **[1 point]**\n",
    "\n",
    "ANSWER:\n",
    "1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 (Writing Code - 30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we'll be working with GPP and SIF data from three separate sites: 1) temperate forest site in the US; 2) tropical forest site in Brazil; and 3) boreal forest site in Russia. The files are saved in the data.zip folder and are called:\n",
    "1. US_temp_gpp_sif.csv\n",
    "2. BR_trop_gpp_sif.csv\n",
    "3. RU_bore_gpp_sif.csv\n",
    "\n",
    "The data are monthly values between 2007 and 2011 - therefore, the number of observations is 60 for each. GPP are in the 1st column and SIF are in the 2nd column.\n",
    "\n",
    "The objective of this exericse is to work out which site has the highest correlation between GPP and SIF data. I.e. the task is to calculate the R value between the GPP and SIF timeseries.\n",
    "\n",
    "You can calculate the correlation using any of the following methods, inlcuding:\n",
    "\n",
    "- np.corrcoef()\n",
    "- scipy.stats.pearsonr (see Exercise 11)\n",
    "- or any of the linear regression methods we learned (Exericses 12 and 13)\n",
    "\n",
    "*Note: Beware of which linear regression methods give you R, and which directly give you R$^{2}$. If you calculate R$^{2}$ then you need to use np.sqrt to get the correlation.*\n",
    "\n",
    "You will get the most marks for making your code as clean and efficient as possible. For example, your code will be \"cleaner\" if you use a for loop to loop over the sites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, in the markdown box below write your logic in normal/plain english to explain the steps you will need to complete this exercise. Think of this as a plan for your script. [5 points out of 30]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOGIC FOR YOUR CODE:** \n",
    "- import libraries\n",
    "- create a filelist using glob.glob\n",
    "- if using a loop, set-up a \"r\" array to save the r for each site within the loop\n",
    "- loop over sites\n",
    "- read in data using pandas and check with printing head() that it's read in correctly\n",
    "- set-up X as GPP\n",
    "- set-up Y as SIF\n",
    "- (optional) plot a linear regression plot using seaborn\n",
    "- calculate R using numpy, scipy.stats pearsonr, or any of the linear regression method to perform the linear regression and save/print the r to answer the question below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now in the code boxes below write the actual python script you need to complete this excercise. [20 points out of 30]** \n",
    "\n",
    "- Do not forget to comment your code **[3 points out of 30]**! (I have given you a head start in the box below).\n",
    "\n",
    "*NOTE! After you complete the coding task, answer the final question in the markdown below based on your calculations **[2 points out of 30]**.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/gpp_sif/data/RU_boreal_gpp_sif.csv', '../data/gpp_sif/data/US_temp_gpp_sif.csv', '../data/gpp_sif/data/BR_trop_gpp_sif.csv']\n"
     ]
    }
   ],
   "source": [
    "# - create filelist\n",
    "filelist = glob.glob('../data/gpp_sif/data/*.csv')\n",
    "print(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - create an empty list to hold the correlation values\n",
    "site_corr = []\n",
    "site_corr_sklearn = []\n",
    "site = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        GPP       SIF\n",
      "0  0.000000 -0.155889\n",
      "1  0.000000 -0.035329\n",
      "2  0.000000  0.211935\n",
      "3  0.000012  0.090419\n",
      "4  0.000078  0.624613\n",
      "('RU', 0.9071430177197362)\n",
      "            GPP       SIF\n",
      "0  1.454290e-05  0.311468\n",
      "1  1.177860e-07  0.455039\n",
      "2  2.293960e-05  0.167898\n",
      "3  1.109360e-04  0.917273\n",
      "4  1.637100e-04  1.811897\n",
      "('US', 0.3863954642715991)\n",
      "        GPP       SIF\n",
      "0  0.000126  1.458244\n",
      "1  0.000122  2.908480\n",
      "2  0.000123  2.251486\n",
      "3  0.000118  1.946829\n",
      "4  0.000115  2.425157\n",
      "('BR', 0.20317746499310485)\n"
     ]
    }
   ],
   "source": [
    "# - loop over sites\n",
    "for f in filelist:\n",
    "    \n",
    "    # - save site just for ease of understanding which site\n",
    "    site.append(f.split('/')[-1].split('_')[0])\n",
    "    \n",
    "    # - read in data\n",
    "    data = pd.read_csv(f)\n",
    "    \n",
    "    # - print data head to check\n",
    "    print(data.head())\n",
    "    \n",
    "    # - use numpy to calculate correlation\n",
    "    site_corr.append(np.corrcoef(data[\"GPP\"].to_numpy(), data[\"SIF\"].to_numpy())[0,1])\n",
    " \n",
    "    # - sklearn\n",
    "    lm = linear_model.LinearRegression()\n",
    "    X = data[\"GPP\"].to_numpy().reshape(-1,1)\n",
    "    y = data[\"SIF\"].to_numpy().reshape(-1,1)\n",
    "    model = lm.fit(X,y)\n",
    "    print(site[-1],model.score(X,y))\n",
    "    site_corr_sklearn.append(np.sqrt(model.score(X,y)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RU', 'US', 'BR']\n",
      "[0.9524405586280628, 0.6216071623393666, -0.4507521103590142]\n",
      "[0.9524405586280628, 0.6216071623393662, 0.45075211035901414]\n"
     ]
    }
   ],
   "source": [
    "# - print out sites and print out correlations\n",
    "print(site)\n",
    "print(site_corr)\n",
    "print(site_corr_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION:\n",
    "\n",
    "1) Based on the R (correlation) value, which site has the highest correlation between GPP and SIF\n",
    "\n",
    "ANSWER: Russian boreal forest site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remember to save your answers and upload them to Canvas by the end of the class. CHECK you have uploaded the right Jupyter Notebook to Canvas. EMAIL yourself a copy of the Jupyter Notebook (or save it to usb) in case something goes wrong with the Canvas submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
